{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from d2l import torch as d2l\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w = torch.tensor([2,-3.4,8,-6.9,8,6,9,4,1,3,-8,-9,5,6,95,78,-63.2,-9,-59])\n",
    "true_b = 4.2\n",
    "features, labels = d2l.synthetic_data(true_w, true_b, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 100\n",
    "data_iter = load_array((features, labels), batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0049,  0.8661, -0.4291,  ...,  0.5213, -1.0603,  1.0477],\n",
       "         [ 0.1916, -1.1214, -0.1970,  ...,  1.9939, -1.1488,  2.3448],\n",
       "         [-0.9712,  0.6821,  0.9975,  ..., -0.2564,  0.2548, -0.5603],\n",
       "         ...,\n",
       "         [ 1.9182, -0.3143, -0.6725,  ...,  2.0395, -0.3485,  0.4892],\n",
       "         [ 0.4977, -0.4629, -0.0276,  ...,  0.4700, -0.0379,  0.3369],\n",
       "         [-0.5820,  1.8617, -0.0119,  ...,  1.3892, -1.6164,  0.1805]]),\n",
       " tensor([[-270.4475],\n",
       "         [  33.6205],\n",
       "         [  86.1437],\n",
       "         [-480.0931],\n",
       "         [-172.0247],\n",
       "         [ -22.1264],\n",
       "         [ 121.3159],\n",
       "         [  26.2295],\n",
       "         [ -26.9932],\n",
       "         [ 163.1523],\n",
       "         [-127.5709],\n",
       "         [-407.4481],\n",
       "         [ 183.4154],\n",
       "         [ 168.3115],\n",
       "         [ -88.0247],\n",
       "         [ -64.5033],\n",
       "         [-163.0512],\n",
       "         [  98.0258],\n",
       "         [ 141.0363],\n",
       "         [  80.5682],\n",
       "         [ 120.3632],\n",
       "         [  79.7196],\n",
       "         [  -9.9310],\n",
       "         [ -63.3411],\n",
       "         [  -5.4618],\n",
       "         [  61.3853],\n",
       "         [  21.3059],\n",
       "         [ 138.0077],\n",
       "         [-127.0328],\n",
       "         [ -66.1456],\n",
       "         [ 193.9071],\n",
       "         [ -48.1703],\n",
       "         [  63.7322],\n",
       "         [  13.5148],\n",
       "         [-272.0569],\n",
       "         [-230.2879],\n",
       "         [ 138.0303],\n",
       "         [ -47.4270],\n",
       "         [  97.6154],\n",
       "         [-120.4166],\n",
       "         [ 266.5132],\n",
       "         [ -83.6091],\n",
       "         [-327.4647],\n",
       "         [-124.6841],\n",
       "         [ -21.3023],\n",
       "         [ 196.4645],\n",
       "         [  18.1984],\n",
       "         [  68.6703],\n",
       "         [ -18.9958],\n",
       "         [ 348.5829],\n",
       "         [ 110.5557],\n",
       "         [ 253.8277],\n",
       "         [-131.1226],\n",
       "         [ 185.0382],\n",
       "         [-187.7150],\n",
       "         [  33.7924],\n",
       "         [ -17.8650],\n",
       "         [  70.0615],\n",
       "         [  18.5205],\n",
       "         [ 182.7134],\n",
       "         [  19.7189],\n",
       "         [ 212.4532],\n",
       "         [ -79.1309],\n",
       "         [-177.4634],\n",
       "         [  17.3218],\n",
       "         [ -17.0870],\n",
       "         [  46.9318],\n",
       "         [-178.8572],\n",
       "         [ 137.4222],\n",
       "         [ -22.2191],\n",
       "         [ 296.7414],\n",
       "         [-295.8358],\n",
       "         [  31.3603],\n",
       "         [-232.4056],\n",
       "         [  88.3197],\n",
       "         [ -48.8756],\n",
       "         [-264.4658],\n",
       "         [  99.4424],\n",
       "         [ -42.3165],\n",
       "         [ -50.2329],\n",
       "         [-121.5456],\n",
       "         [-144.0923],\n",
       "         [ 242.8853],\n",
       "         [-182.5272],\n",
       "         [-129.3275],\n",
       "         [-182.1308],\n",
       "         [ 225.9641],\n",
       "         [ 110.1532],\n",
       "         [  -8.5519],\n",
       "         [ -85.4043],\n",
       "         [  69.4850],\n",
       "         [  38.1633],\n",
       "         [  57.5708],\n",
       "         [ -81.4751],\n",
       "         [ 185.6071],\n",
       "         [ -88.5005],\n",
       "         [-130.5243],\n",
       "         [-110.7157],\n",
       "         [ 208.1653],\n",
       "         [-210.3671]])]"
      ]
     },
     "execution_count": 478,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(nn.Linear(len(true_w),1))\n",
    "\n",
    "net[0].weight.data.normal_(0,0.01)\n",
    "net[0].bias.data.fill_(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "\n",
    "trainer = torch.optim.SGD(net.parameters(),lr = 0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w is: tensor([[  2.0265,  -3.4116,   8.0198,  -6.8998,   8.0014,   5.9629,   8.9955,\n",
      "           4.0141,   1.0106,   2.9767,  -7.9899,  -8.9936,   4.9704,   5.9913,\n",
      "          94.7986,  77.8076, -63.0672,  -8.9654, -58.8695]]) \n",
      " b is : tensor([4.2012])\n",
      "epoch 1, loss 0.114824\n",
      "w is: tensor([[  2.0002,  -3.4000,   7.9999,  -6.8999,   8.0002,   5.9999,   9.0001,\n",
      "           4.0004,   1.0000,   2.9999,  -8.0000,  -9.0001,   4.9995,   5.9999,\n",
      "          94.9996,  77.9999, -63.1999,  -8.9997, -58.9998]]) \n",
      " b is : tensor([4.1999])\n",
      "epoch 2, loss 0.000101\n",
      "w is: tensor([[  1.9999,  -3.4003,   8.0001,  -6.8999,   8.0000,   6.0002,   9.0002,\n",
      "           4.0002,   1.0000,   3.0001,  -8.0003,  -9.0001,   4.9996,   5.9999,\n",
      "          95.0000,  78.0000, -63.2000,  -8.9998, -59.0002]]) \n",
      " b is : tensor([4.1999])\n",
      "epoch 3, loss 0.000101\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 3\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        l = loss(net(X), y)\n",
    "        trainer.zero_grad()\n",
    "        l.backward()\n",
    "        #trainer.zero_grad()\n",
    "        trainer.step()\n",
    "        #trainer.zero_grad()\n",
    "\n",
    "    l = loss(net(features), labels)\n",
    "    print('w is:', net[0].weight.data ,'\\n b is :', net[0].bias.data)\n",
    "    print(f'epoch {epoch + 1}, loss {l:f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
